# SpringSecurity相关

## 开启csrf与xss

### 防止XSS
`XSS` 是跨站脚本攻击, 类似提交一个文本, 但是文本内容是一段js代码, 再次渲染到页面后可能会被浏览器执行，同时收集用户cookie并通过iframe发送到第三方收集服务器；主要预防手段是通过`过滤器(Filter)`将用户提交的数据进行html编码。

1.引入依赖包：
```xml
<dependency>
    <groupId>org.jsoup</groupId>
    <artifactId>jsoup</artifactId>
    <version>1.11.3</version>
</dependency>
```

2.代码编写
本质是编写`Filter`，有三个地方可以编写过滤器
```yaml
1. 编写servlet的过滤器
2. 在zuul网关/gateway网关编写过滤器
3. 在spring security编写过滤器
```
XSS防御实现方式也有两种
```yaml
1. script脚本过滤清除 -> JsoupUtil.clean(val)
2. 进行HTML编码 -> HtmlUtils.htmlEscape(val)
```
目前实现了「servlet方式」和「zuul方式」过滤器的代码
代码地址：
[servlet过滤器](https://github.com/asan3524/yiran/tree/develop/yiran-zipkin-elk-demo/demo-zipkin-consumer/src/main/java/com/yiran/zipkin/consumer/filter)
[zuul过滤器](https://github.com/asan3524/yiran/blob/develop/yiran-zipkin-elk-demo/demo-zipkin-gateway/src/main/java/com/yiran/zipkin/zuul/filter)

### SpringSecurity开启csrf
首先csrf不会拦截`GET`，`HEAD`，`TRACE`，`OPTIONS`请求，只会拦截对资源有修改动作的`PUT`，`DELETE`，`POST`等。

添加依赖
```xml
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-security</artifactId>
</dependency>

<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-oauth2</artifactId>
</dependency>

<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-autoconfigure</artifactId>
</dependency>
```

实现也分为两种方式
```bash
1. 前后分离模式

2. 基于后端模版, 比如jsp/freemarker/thymeleaf
   2.1 表单提交
   2.2 ajax提交
```

步骤如下：

- **开启csrf配置 (默认是开启的)**

```java
@Configuration
@EnableWebSecurity
public class SecurityConfig extends WebSecurityConfigurerAdapter {
    @Override
    protected void configure(HttpSecurity http) throws Exception {
    http.
        // 省略一些配置项...
        
        /**
         * 针对前后分离的项目, 需要从cookie中读取csrfToken, 但它的cookie默认具有cookieHttpOnly属性, js无法操作, 
         * 所以关闭cookie的 HttpOnly 属性
         *
         * 针对后端模版的项目, 需使用HttpSessionCsrfTokenRepository
         */
        .csrf().csrfTokenRepository(CookieCsrfTokenRepository.withHttpOnlyFalse());
    
    }
}

```

- **定义哪些url需要被`CsrfFilter`拦截**

默认有一个`DefaultRequiresCsrfMatcher`，但它会拦截全部url
除了`GET`，`HEAD`，`TRACE`，`OPTIONS`。
如有需求则可以自定义一个
```java
public class CsrfSecurityRequestMatcher implements RequestMatcher {
    ...
}
```
代码地址：
[CsrfSecurityRequestMatcher](https://github.com/asan3524/yiran/blob/develop/yiran-base/base-sso/src/main/java/com/yiran/base/sso/filter/CsrfSecurityRequestMatcher.java)

- **基于后端模版 `thymeleaf`**

首先配置csrf的repository (如何存储scrfToken)，此处使用`HttpSessionCsrfTokenRepository`，它将token存储在Session里。

(1) 如果是表单
首先配置存储类
```java
http
.csrf().csrfTokenRepository(HttpSessionCsrfTokenRepository);
```
然后在表单中加入隐藏域（名字不明白含义就不要改，有些是过滤器默认从cookie或请求里取值的name，自己可以配置）
```html
<form action="${loginUrl}" method="post">
...
<input type="hidden" name="${_scrf.parameterName}" value="${_csrf.token}"/>
</form>
```

(2) 如果是ajax
我们的所有请求都可通过ajax发送请求
那么就可以有一个公共模版，比如名字叫做 `layout.html`，里面的ajax包含一个beforeSend的钩子函数，会给所有ajax添加Header
```html
<meta name="_csrf" content="${_csrf.token}"/>
<meta name="_csrf_header" content="${_csrf.headerName}"/>
 
<script>
 
    var token = $("meta[name='_csrf']").attr("content");
    var header = $("meta[name='_csrf_header']").attr("content");
    
    //意思是所有的ajax请求, 在发送前都会添加token到header
    $.ajaxSetup({
        beforeSend: function (xhr) {
            if(header && token ){
                xhr.setRequestHeader(header, token);
            }
        }}
    );
</script>
```

- **前后分离**

注意（一般来说只要不改配置，无须关心）：
```bash
// 基于Cookie时，CookieCsrfTokenRepository 里默认的名字
headerName = "X-XSRF-TOKEN"
cookieName = "XSRF-TOKEN"
parameterName = "_csrf"

// 基于Session时，HttpSessionCsrfTokenRepository 里默认的名字
headerName = "X-CSRF-TOKEN"
parameterName = "_csrf"
```

前后分离需要使用到cookie来拿到`csrfToken`，那么需要如下配置。
```java
http
    .csrf().csrfTokenRepository(CookieCsrfTokenRepository.withHttpOnlyFalse())
```

从cookie里取出，并放置到ajax请求参数里；
也可以放到Header里，`CsrfFilter`会默认先从Header里获取，没有再到请求参数里获取。
```javascript
function getCookie(name){
    var strcookie = document.cookie;//获取cookie字符串
    var arrcookie = strcookie.split("; ");//分割
    //遍历匹配
    for ( var i = 0; i < arrcookie.length; i++) {
        var arr = arrcookie[i].split("=");
        if (arr[0] == name){
            return arr[1];
        }
    }
    return "";
}

// 获取cookie中的scrfToken
var _csrf_token = getCookie("XSRF-TOKEN");

// ajax发送时把参数带上, 可以放到请求参数里, 也可以在Header，CookieCsrfTokenRepository会自动处理
// 添加到参数里时，参数名: _csrf
// 添加到Header里时，
$.post(url, {
    userId : "123456",
    name: "duyu"
    _csrf : _csrf_token
}, function(datas) {
    // 异步回调
})
```


## SpringSecurity如何做https

- 生成SSL证书

使用jdk的keytool工具，生成服务端证书。
```bash
keytool -genkey -alias imageanalysis -storetype PKCS12 -keypass 123456 -keyalg RSA -keysize 1024 -validity 365 -keystore /xxx/xxx/imageanalysis.keystore -storepass 123456
```

将生成的`imageanalysis.keystore`放到项目的`resources`目录，然后配置`application.yml`
```yml
server:
  ssl:
    #证书路径
    key-store: classpath:imageanalysis.keystore
    #填写生成时的密码
    key-store-password: 123456
    #类型
    key-store-type: PKCS12
    #别名
    key-alias: imageanalysis
  #htts端口
  port: 8433
  #http端口
  http:
    port: 8080
```

比如springboot默认使用内嵌tomcat(当然也可以使用jetty)，那么需要注入一个配置
```java
@Configuration
public class WebConfig extends WebMvcConfigurationSupport {

    @Value("${server.port}")
    private int serverPort;

    @Value("${server.http.port}")
    private int serverHttpPort;
    
    @Bean
    public EmbeddedServletContainerFactory servletContainer() {
        TomcatEmbeddedServletContainerFactory tomcat = new TomcatEmbeddedServletContainerFactory() {
            @Override
            protected void postProcessContext(Context context) {
                SecurityConstraint securityConstraint = new SecurityConstraint();
                securityConstraint.setUserConstraint("CONFIDENTIAL");
                SecurityCollection collection = new SecurityCollection();
                collection.addPattern("/*");
                securityConstraint.addCollection(collection);
                context.addConstraint(securityConstraint);
            }
        };

        tomcat.addAdditionalTomcatConnectors(initiateHttpConnector());
        return tomcat;
    }

    private Connector initiateHttpConnector() {
        Connector connector = new Connector("org.apache.coyote.http11.Http11NioProtocol");
        connector.setScheme("http");
        //需要重定向的http端口
        connector.setPort(serverHttpPort);
        connector.setSecure(false);
        //设置重定向到https端口
        connector.setRedirectPort(serverPort);
        return connector;
    }
}
```


# ELK单节点部署与使用

## 已制作的镜像备份地址
```yaml
镜像文件所在机器: 192.168.80.71
目录: /root/yiran/image-tools/image
镜像备份文件名: 
    base-elk.tar.gz
    image-yiran-base-zipkin.tar.gz
镜像地址: 
    whayercloud.registry:5000/elk:latest
    whayercloud.registry:5000/zipkin:latest
```

## zipkin使用

<font color='orange'>zipkin在`springcloud2.x`已不推荐自己创建`Zipkin Server`服务, 需要使用编译好的jar</font>

- 安装zipkin docker

```shell
docker run -d -p 9411:9411 openzipkin/zipkin
```

- 添加依赖

```xml
<dependency>
	<groupId>org.springframework.cloud</groupId>
	<artifactId>spring-cloud-starter-zipkin</artifactId>
</dependency>
```

- yml配置

```yml
spring: 
  sleuth: 
    feign: 
      enabled: true
    sampler: 
      # 采样率, 1.0表示全量采集
      probability: 1.0
    web: 
      client: 
        enabled: true
  zipkin: 
    enabled: true
    # zipkin的部署地址
    base-url: http://192.168.80.81:9411/
    service: 
      name: ${spring.application.name}
    sender: 
      # 支持http, rabbitmq, kafka, 后期采用kafka
      type: web   
```

- zipkin访问地址

部署在哪台机器请自行修改IP
```yml
http://192.168.80.81:9411/
```

## ELK部署安装

- 下载镜像

```shell
docker pull sebp/elk
```
- 运行条件

这是一个聚合镜像, 要求Docker至少得分配3GB的内存; Elasticsearch至少需要单独2G的内存; `vm.max_map_count`至少需要`262144`
```shell
# linux按如下操作, 后期重新制作镜像 
sudo vi /etc/sysctl.conf
# 添加如下
vm.max_map_count=262144
# 查看是否生效
sysctl -p

```

- 启动`ELK` 

|- 端口  |- 作用 |
:----:|:----
`5601`|Kibana映射地址
`9200`|ES映射地址
`5044`|Logstash Beats界面映射地址
`9250`|Logstash监听搜集日志的端口(可自行随意指定)<br>目前使用tcp方式从服务节点发送日志到logstash, 不采用物理文件日志搜集方式, 后期会添加kafka队列作为缓冲
```shell
### 注意挂载配置文件目录
docker run -itd -p 9250:9250 -p 5601:5601 -p 9200:9200 -p 5044:5044 -v /Users/apple/idea/spring-cloud-bingo/config:/data --name elk sebp/elk:latest 
```

稍微注意下, 由于需要配置`logstash`如何在`elasticsearch`创建索引, 所以需要定义`logstash.conf`文件, 在`ELK`启动时需要指定, 配置文件如下

- `logstash.conf` 配置

```conf
# For detail structure of this file
# Set: https://www.elastic.co/guide/en/logstash/current/configuration-file-structure.html
input {
  # For detail config for log4j as input,
  # See: https://www.elastic.co/guide/en/logstash/current/plugins-inputs-log4j.html
  tcp {
    mode => "server"
    host => "127.0.0.1"
    port => 9250 #logstash监听地址
    codec => "json" #发送格式需是json
  }
}
filter {
  ## 过滤条件后期添加, 也可以在logback.xml中预先过滤一次
  #Only matched data are send to output.
}
output {
  # For detail config for elasticsearch as output,
  # See: https://www.elastic.co/guide/en/logstash/current/plugins-outputs-elasticsearch.html
  elasticsearch {
    action => "index"          #The operation on ES
    hosts  => ["127.0.0.1:9200"] #ElasticSearch host, can be array.
    index  => "applog"         #The index to write data to.
  }
}
```

- 进入容器重启`logstash`
目的是让`logstash`应用`logstash.conf`配置文件
<font color='red'> 此处需要重新制作镜像, 将启动配置`logstash.conf`写入Dockerfile</font>

```shell
docker exec -it elk /bin/bash
#停止logstash
service logstash stop
#启动测试是否与es连接
/opt/logstash/bin/logstash -e 'input { stdin { } } output { elasticsearch { hosts => ["localhost"] } }'
#随便在控制台输入字符, 然后进es地址查看
#localhost:9200/_search?pretty

#最后带配置启动logstash
/opt/logstash/bin/logstash --path.data /tmp/logstash/data -f /data/logstash.conf
```

## SpringCloud与Logstash集成
通过将日志模块搜集的日志以

- 依赖

```xml
<!-- 支持tcp和udp -->
<dependency>
	<groupId>net.logstash.logback</groupId>
	<artifactId>logstash-logback-encoder</artifactId>
	<version>5.3</version>
</dependency>
```

- logback.xml

详情请见工程

- 配置

<font color='red'>注意此节点需要配置到 `bootstrap.yml`;
同时`logback.remote.xml`名字固定, 否则导致日志xml配置提前解析, 会找不到`logstash.tcp.destination`填写的值</font>
```yml
logstash: 
  tcp:
    # 表示logstash的日志监听地址和端口
    destination: 127.0.0.1:9250
logging: 
  config: classpath:logback.remote.xml
```

## 集群部署方案
方案1：日志缓存为redis
![](http://images2018.cnblogs.com/blog/907596/201804/907596-20180425172936102-2010066031.png)

方案2：日志缓存为kafka
![](http://images2015.cnblogs.com/blog/927655/201612/927655-20161215134029636-1747126363.png)

由于在应用服务器上部署`logstash`进程会导致和应用进程竞争资源, 为避免引入额外因素, 应用服务器只做读取转发, 所以出现如下角色：
`shipper`: 运行在应用服务器上的，尽量减轻运行压力，只做读取和转发
`indexer`: 运行在独立服务器上，完成数据解析处理，负责写入 Elasticsearch

由于内存金贵, 目前选择第二种`kafka`作为缓存与传输层, 
同时indexer的输入请参考: [input](https://www.elastic.co/guide/en/logstash/current/input-plugins.html) ; 输出 : [output](https://www.elastic.co/guide/en/logstash/current/output-plugins.html) ; filter : [filter](https://www.elastic.co/guide/en/logstash/6.4/filter-plugins.html) ; 
相关依赖项 : [logstash reference](https://www.elastic.co/guide/en/logstash/6.4/index.html) 

备注:
对ELK若有疑问, 可自行参考 [elk-docker
](https://elk-docker.readthedocs.io/)




